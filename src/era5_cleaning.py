"""author: Robin Shindelmandate: 2025-02-05description: ERA5 Gulf of Alaska data set cleaning."""import pandas as pdimport seaborn as snsimport xarray as xrfrom mpl_toolkits.basemap import Basemapimport matplotlib.pyplot as pltimport numpy as npfrom sklearn.preprocessing import MinMaxScaler# ----------------------------------------------------------------------------## Export GRIB to CSV# ds = xr.load_dataset('../data/raw/ERA5/gulf_ak.grib', engine='cfgrib')# df = ds.to_dataframe()# df = df.loc['2024-01-01']# df.to_csv('../data/raw/ERA5/gulf_of_ak_era5.csv')# ----------------------------------------------------------------------------# Load small data setdf = pd.read_csv('../data/raw/ERA5/gulf_of_ak_era5.csv')# ----------------------------------------------------------------------------# Visualize pre-cleaningprint(df[['d', 'q', 'crwc', 'cswc', 't', 'u', 'v']].describe())sns.histplot(data=df, x='d')plt.title("Divergence from 800 -- 1000 hPa")plt.show()sns.boxplot(data=df, x='t')plt.title("Temperature ")plt.show()sns.boxplot(data=df, x='d')plt.title("Gulf of Alaska Divergence")plt.xlabel("Divergence ")plt.show()# ----------------------------------------------------------------------------# Map projection of Wind U-Component speedlat_low = min(df.latitude)lat_high = max(df.latitude)long_low = min(df.longitude)long_high = max(df.longitude)m = Basemap(width=12000000, height=9000000, projection='lcc',            resolution='c',lat_1=10,lat_2=30,lat_0=50,lon_0=-115.0)m.drawcoastlines()m.drawmapboundary(fill_color='aqua')m.fillcontinents(color='grey',lake_color='aqua')u_pivot = df.pivot_table(index='latitude', columns='longitude', values='u')grid_lat = u_pivot.index.valuesgrid_long = u_pivot.columns.valuesgrid_u = u_pivot.valueslon, lat = np.meshgrid(grid_long, grid_lat)x, y = m(lon, lat)c = m.pcolormesh(x, y, grid_u, shading='warm', cmap='coolwarm')plt.colorbar(c, label="Speed m/s^-1")plt.title("Wind U-Component")plt.show()# ----------------------------------------------------------------------------# Cleaning stepsdf['time'] = pd.to_datetime(df['time'])df['isobaricInhPa'] = df['isobaricInhPa'].astype('int64')df = df.drop(['number', 'step', 'valid_time'], axis=1)df['t'] = df['t'].apply(lambda x: (x-273.15) * 1.8 + 32)# df = df[(df.d > -0.0005) & (df.d < 0.0005)]  # If you want to get some outliers# Export a nice clean csvdf.to_csv("../data/clean/ERA5/gulf_of_ak_clean.csv", index=False)# ----------------------------------------------------------------------------# Make the dataframe purely quantitative and normalized using Min-Maxprint('\n', df.loc[:, 'd':'v'].describe())qualitative_cols = ['time', 'latitude', 'longitude']df = df.drop(qualitative_cols, axis=1)scaler = MinMaxScaler()df[['d', 'q', 'crwc', 'cswc', 't', 'u', 'v']] = scaler.fit_transform(df[['d', 'q', 'crwc', 'cswc', 't', 'u', 'v']])df.to_csv("../data/clean/ERA5/gulf_of_ak_normalized.csv", index=False)